{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6580210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install mlx-lm matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df88fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_flatten\n",
    "from mlx_lm import generate, load\n",
    "from mlx_lm.tuner import TrainingArgs, datasets, linear_to_lora_layers, train\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05beab2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba509d8b3f5e4adab0e6d6bb45ad5cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b8340992484d6e895280cde0842e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f8443214544e6f866895d8f9147c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08059419350f4080a29e533d9dae5c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61287ccb3cc6455cab24a3def49535f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2b9bfa29644546b099773bf17a233c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5e8e71895545368a41a1c5d5fa8297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220c4493f95046afbf76046588e6e4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e31f44201b40908e666374d7d38aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a542b1d72368492cba1f378410ce2ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sample_finetune.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"mlx-community/Phi-3-mini-128k-instruct-4bit\"\n",
    "model, tokenizer = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23039e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Fine-tuning in machine learning refers to a process where a pre-trained model, which has already been trained on a large dataset, is further trained (or \"fine-tuned\") on a smaller, more specific dataset to adapt it to a particular task or domain. This is often done to improve performance on a specific problem or to make the model more efficient in handling a particular type of data or task. The pre-trained model, which has already learned a general understanding of the problem space, is adjusted to better suit the specific needs of the task at hand. This is particularly common in deep learning, where large, pre-trained neural networks are used as a starting point for a wide range of applications. The process involves continuing the training of the model on a smaller, task-specific dataset, often with a lower learning rate, to adjust the weights and biases to better perform on the specific task. This method leverages the general knowledge the model has already acquired and adapts it to the nuances of the new task, often leading to better performance than training a model from scratch. It'ries the model's ability to generalize and apply learned patterns to the new task. Fine-tuning can be applied\n",
      "==========\n",
      "Prompt: 13 tokens, 4.107 tokens-per-sec\n",
      "Generation: 256 tokens, 37.392 tokens-per-sec\n",
      "Peak memory: 6.544 GB\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is fine-tuning in machine learning?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f289ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = \"adapters\"\n",
    "os.makedirs(adapter_path, exist_ok=True)\n",
    "adapter_config_path = os.path.join(adapter_path, \"adapter_config.json\")\n",
    "adapter_file_path = os.path.join(adapter_path, \"adapters.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13835493",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    "    \"num_layers\": 8,\n",
    "    \"lora_parameters\": {\n",
    "        \"rank\": 8,\n",
    "        \"scale\": 20.0,\n",
    "        \"dropout\": 0.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e8c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adapter_config_path, \"w\") as f:\n",
    "    json.dump(lora_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f01e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairseq-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
